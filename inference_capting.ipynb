{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNwux1fQ6dgHOcIYJAGFM5+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DqoJXSc0OrEk","executionInfo":{"status":"ok","timestamp":1730978505365,"user_tz":-180,"elapsed":943,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"bbdc9db3-e1b6-46d5-deb3-a4e759defb42"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'VLM_Converter'...\n","remote: Enumerating objects: 17, done.\u001b[K\n","remote: Counting objects: 100% (17/17), done.\u001b[K\n","remote: Compressing objects: 100% (12/12), done.\u001b[K\n","remote: Total 17 (delta 4), reused 13 (delta 2), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (17/17), 8.66 KiB | 2.89 MiB/s, done.\n","Resolving deltas: 100% (4/4), done.\n","/content/VLM_Converter\n"]}],"source":["!git clone https://github.com/Mike030668/VLM_Converter.git\n","%cd VLM_Converter"]},{"cell_type":"markdown","source":["# Step 1: Import Necessary Libraries\n","Begin by importing the necessary libraries and modules."],"metadata":{"id":"RMmMeMuwUe-l"}},{"cell_type":"code","source":["# Import standard libraries\n","import os\n","import torch\n","import gc\n","import re\n","\n","# Import your models and processors\n","#from transformers import T5Tokenizer, T5ForConditionalGeneration\n","#from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n","\n","# Import your captioner class\n","from vlm_captioners import Llava_Flan_captioner  # Ensure this is accessible\n","from load_models import load_vlm_model, load_text_model"],"metadata":{"id":"tzrSscDsUjBH","executionInfo":{"status":"ok","timestamp":1730978530502,"user_tz":-180,"elapsed":14433,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F94QNLpVVgCj","executionInfo":{"status":"ok","timestamp":1730978533562,"user_tz":-180,"elapsed":275,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"c24b1bea-361c-460c-ec3c-d2e44869be3e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n"]}]}]}